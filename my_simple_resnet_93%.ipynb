{"cells":[{"cell_type":"markdown","source":["#树叶分类任务\n","\n","\n"],"metadata":{"id":"DF8p1c-4Tk9O"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"wEM1rSmOgMjH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679407178858,"user_tz":-480,"elapsed":5121,"user":{"displayName":"Hikari Lianqing","userId":"02586460300598127694"}},"outputId":"68ccfbbb-f010-4177-be02-27afe71e8167"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["#colab 挂载\n","from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","source":["!cp \"/content/drive/MyDrive/LeavesClassification/images.zip\" \"/content\"\n","%cd \"/content\"\n","!unzip -q \"images.zip\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kuq3ioUKcTMw","executionInfo":{"status":"ok","timestamp":1679407204360,"user_tz":-480,"elapsed":25504,"user":{"displayName":"Hikari Lianqing","userId":"02586460300598127694"}},"outputId":"9e2ca2d3-4414-4b97-afa8-7a0807e26115"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","replace images/0.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"]}]},{"cell_type":"code","source":["#看一看自己能用啥GPU\n","!/opt/bin/nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4a2dMEC4RI29","executionInfo":{"status":"ok","timestamp":1679407204360,"user_tz":-480,"elapsed":6,"user":{"displayName":"Hikari Lianqing","userId":"02586460300598127694"}},"outputId":"1df59705-55bd-4718-fed9-24e2ac6e6b11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Mar 21 14:00:03 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   73C    P0    33W /  70W |  11259MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vG4leKSbgtER","executionInfo":{"status":"ok","timestamp":1679407212652,"user_tz":-480,"elapsed":8294,"user":{"displayName":"Hikari Lianqing","userId":"02586460300598127694"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"08c85371-e711-4a03-fb64-1613552bd660"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: timm in /usr/local/lib/python3.9/dist-packages (0.6.12)\n","Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.9/dist-packages (from timm) (1.13.1+cu116)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from timm) (6.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from timm) (0.14.1+cu116)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.9/dist-packages (from timm) (0.13.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.7->timm) (4.5.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (4.65.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (3.10.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (2.27.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision->timm) (1.22.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->timm) (8.4.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (2.0.12)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: resnest in /usr/local/lib/python3.9/dist-packages (0.0.6b20230321)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from resnest) (8.4.0)\n","Requirement already satisfied: nose in /usr/local/lib/python3.9/dist-packages (from resnest) (1.3.7)\n","Requirement already satisfied: fvcore in /usr/local/lib/python3.9/dist-packages (from resnest) (0.1.5.post20221221)\n","Requirement already satisfied: iopath in /usr/local/lib/python3.9/dist-packages (from resnest) (0.1.10)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from resnest) (1.10.1)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from resnest) (1.13.1+cu116)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from resnest) (4.65.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from resnest) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from resnest) (2.27.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.0.0->resnest) (4.5.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from fvcore->resnest) (6.0)\n","Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.9/dist-packages (from fvcore->resnest) (0.1.8)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.9/dist-packages (from fvcore->resnest) (2.2.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.9/dist-packages (from fvcore->resnest) (0.8.10)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.9/dist-packages (from iopath->resnest) (2.7.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->resnest) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->resnest) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->resnest) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->resnest) (2022.12.7)\n"]}],"source":["#必要的包载入\n","import torch\n","import pandas as pd\n","import numpy as np\n","from torch.utils import data\n","from PIL import Image\n","from torchvision import transforms\n","from torch import nn\n","import torchvision\n","from torch.nn import functional as F\n","from torchsummary import summary\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","from tqdm import tqdm\n","import albumentations\n","from albumentations.pytorch.transforms import ToTensorV2\n","!pip install timm\n","import timm\n","!pip install resnest --pre\n","from resnest.torch import resnest50"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-MQjml9UiWSX","executionInfo":{"status":"ok","timestamp":1679407212653,"user_tz":-480,"elapsed":6,"user":{"displayName":"Hikari Lianqing","userId":"02586460300598127694"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"10e6c032-1c94-4302-8e25-0d830556e086"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f7c603499f0>"]},"metadata":{},"execution_count":35}],"source":["##设置超参数\n","train_csv_address=\"/content/drive/MyDrive/LeavesClassification/train.csv\"\n","test_csv_address=\"/content/drive/MyDrive/LeavesClassification/test.csv\"\n","submission_address=\"\"\n","root=\"/content/\"  #把图片放在工作目录会更好\n","#root=\"/content/drive/MyDrive/LeavesClassification/\" #照片存放的位置\n","batch_size=64\n","output_size=176 #输出的维度，也就是类别数\n","lr=0.0001\n","weight_decay=1e-4\n","if(torch.cuda.is_available()):#是否需要使用GPU\n","  cuda=1\n","else:\n","  cuda=0\n","epochs=50 #训练轮次\n","load_epoch=0 #载入的模型对应的轮次\n","model_save_root=\"/content/drive/MyDrive/LeavesClassification/models/\"\n","model_load_name=\"resnet34_epoch{}.pth\".format(load_epoch) #load的时候记得改这个名字\n","load=0  #是否需要载入模型\n","train_rate=0.7  #训练集所占的比例\n","num_workers=2 #工作进程数\n","torch.manual_seed(42)"]},{"cell_type":"markdown","source":["#数据预处理\n","数据预处理需要完成的事情是建立图像与标签之间的对应关系，同时将训练集再划分出一部分作为验证集"],"metadata":{"id":"q3sKnK9XUMks"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"n9ff25uKrXQx"},"outputs":[],"source":["##数据预处理\n","\n","#载入数据\n","train_csv=pd.read_csv(train_csv_address)\n","test_csv=pd.read_csv(test_csv_address)\n","\n","#获取label中的所有类别\n","label_list=list(np.unique(list(train_csv[\"label\"]))) #获取列表中不重复的元素（获取所有标签）\n","label_to_id = dict((c, i) for i, c in enumerate(label_list)) #通过字典构建标签到独热编码的映射\n","id_to_label={v : k for k, v in label_to_id.items()}\n","\n","#将图片对应的标签转换为独热编码\n","train_label_list=list(train_csv[\"label\"])\n","\n","for i,c in enumerate(train_label_list): #按照字典查找标签对应的独热编码\n","  train_label_list[i]=label_to_id[c]\n","\n","#定义训练数据和标签\n","data_image=np.array(list(train_csv[\"image\"]))\n","data_label=np.array(train_label_list)\n","test_image=np.array(list(test_csv[\"image\"]))\n","\n","#设置两个相同的种子，以同样的方式打乱图像和标签，保证图像和标签的对应关系\n","np.random.seed(1234)\n","np.random.shuffle(data_image)\n","np.random.seed(1234)\n","np.random.shuffle(data_label)\n","\n","#划分数据集\n","train_image=data_image[:int(len(data_image)*train_rate)]\n","train_label=data_label[:int(len(data_label)*train_rate)]\n","val_image=data_image[int(len(data_image)*train_rate):]\n","val_label=data_label[int(len(data_label)*train_rate):]\n"]},{"cell_type":"markdown","source":["#定义数据集与迭代器"],"metadata":{"id":"JxHOSLKiUqcz"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"TLobIV1HrKbU"},"outputs":[],"source":["##定义数据集与迭代器\n","\n","#定义图像变换\n","'''train_transform=albumentations.Compose(\n","        [\n","            albumentations.HorizontalFlip(p=0.5),\n","            albumentations.VerticalFlip(p=0.5),\n","            albumentations.Rotate(limit=180, p=0.7),\n","            albumentations.RandomBrightnessContrast(),\n","            albumentations.ShiftScaleRotate(\n","                shift_limit=0.25, scale_limit=0.1, rotate_limit=0\n","            ),\n","            albumentations.Normalize(\n","                [0.485, 0.456, 0.406], [0.229, 0.224, 0.225],\n","                max_pixel_value=255.0, always_apply=True\n","            ),\n","            ToTensorV2(p=1.0),\n","        ]\n",")'''\n","train_transform=transforms.Compose([\n","    transforms.RandomHorizontalFlip(p=0.5),\n","    transforms.RandomVerticalFlip(p=0.5),\n","    transforms.RandomRotation(180),\n","    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5),\n","    transforms.RandomResizedCrop(224, scale=(0.08, 1.0), ratio=(3.0 / 4.0, 4.0 / 3.0)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.475, 0.451, 0.390], std=[0.261, 0.255, 0.259])#借用了ImageNet的数据分布\n","])\n","\n","val_transform=transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.475, 0.451, 0.390], std=[0.261, 0.255, 0.259])#借用了ImageNet的数据分布\n","])\n","test_transform=val_transform\n","\n","#定义数据集\n","class MyDataset(data.Dataset):\n","  def __init__(self,input_image,transform,mode=\"train\",input_label=None):\n","    self.image=input_image\n","    self.label=input_label\n","    self.transform=transform\n","    self.mode=mode\n","\n","  def __getitem__(self,index):\n","    if self.mode==\"train\":\n","      image_address=root+self.image[index]#获取图片地址\n","      image=Image.open(image_address) #打开图片\n","      image=self.transform(image)\n","      label=torch.tensor(self.label[index]) #获取标签\n","      return image,label\n","    elif self.mode==\"val\":\n","      image_address=root+self.image[index]#获取图片地址\n","      image=Image.open(image_address) #打开图片\n","      image=self.transform(image)\n","      label=torch.tensor(self.label[index]) #获取标签\n","      return image,label\n","    else:\n","      image_address=root+self.image[index]#获取图片地址\n","      image=Image.open(image_address) #打开图片\n","      image=self.transform(image)\n","      return image\n","\n","  def __len__(self):\n","    return len(self.image)\n","\n","#实例化数据集，定义迭代器\n","train_set=MyDataset(train_image,train_transform,mode=\"train\",input_label=train_label)\n","train_iter=data.DataLoader(\n","    train_set,\n","    batch_size=batch_size,\n","    shuffle=True,\n","    num_workers=num_workers\n",")\n","val_set=MyDataset(val_image,val_transform,mode=\"val\",input_label=val_label)\n","val_iter=data.DataLoader(\n","    val_set,\n","    batch_size=batch_size,\n","    shuffle=True,\n","    num_workers=num_workers\n",")\n","test_set=MyDataset(test_image,test_transform,mode=\"test\")\n","test_iter=data.DataLoader(\n","    test_set,\n","    batch_size=batch_size,\n","    shuffle=False,\n","    num_workers=num_workers\n",")\n","#next(iter(train_iter))"]},{"cell_type":"markdown","source":["#定义网络"],"metadata":{"id":"dmSuqUYNUy2n"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"MwENHyE_zxRq"},"outputs":[],"source":["##定义网络\n","\n","#采用ResNet18作为网络进行训练\n","#定义小卷积块,沿用VGG中卷积层的设计\n","class Residual(nn.Module):\n","  def __init__(self,input_channels,num_channels,use_1x1conv=False,strides=1):\n","    super().__init__()  #调用基类的初始化方法\n","    self.conv1=nn.Conv2d(input_channels,num_channels,kernel_size=3,padding=1,stride=strides)\n","    self.conv2=nn.Conv2d(num_channels,num_channels,kernel_size=3,padding=1)\n","    if use_1x1conv: #1x1的卷积层用于调整通道和分辨率，如通道数由3变为6，输出高宽减半：Residual(3,6, use_1x1conv=True, strides=2)\n","      self.conv3=nn.Conv2d(input_channels,num_channels,kernel_size=1,stride=strides)\n","    else:\n","      self.conv3=None\n","    \n","    self.bn1=nn.BatchNorm2d(num_channels)\n","    self.bn2=nn.BatchNorm2d(num_channels)\n","  \n","  #前向传播，分别经过：卷积层1，批量规范化层1，ReLU，卷积层2，批量规范化层2，残差连接\n","  def forward(self,X):\n","    Y = F.relu(self.bn1(self.conv1(X)))\n","    Y = self.bn2(self.conv2(Y))\n","    if self.conv3:\n","      X = self.conv3(X)\n","    Y += X\n","    return F.relu(Y)\n","\n","\n","#定义大卷积块\n","def resnet_block(input_channels,num_channels,num_residuals,first_block=False):\n","  blk=[]\n","  for i in range(num_residuals):\n","    if i==0 and not first_block:  #如果是第一个卷积块，那么\n","      blk.append(Residual(input_channels,num_channels,use_1x1conv=True,strides=2))\n","    else:\n","      blk.append(Residual(num_channels,num_channels))\n","  return blk\n","\n","b1=nn.Sequential(nn.Conv2d(3,64,kernel_size=7,stride=2,padding=3),\n","                 nn.BatchNorm2d(64),\n","                 nn.ReLU(),\n","                 nn.MaxPool2d(kernel_size=3,stride=2,padding=1))\n","b2=nn.Sequential(*resnet_block(64, 64, 2, first_block=True))\n","b3 = nn.Sequential(*resnet_block(64, 128, 2))\n","b4 = nn.Sequential(*resnet_block(128, 256, 2))\n","b5 = nn.Sequential(*resnet_block(256, 512, 2))\n","\n","#这里可以选择采用自己搭建的resnet18,效果一样，把下面的注释去掉，再把预训练模型载入注释掉\n","'''net=nn.Sequential(b1,b2,b3,b4,b5,nn.AdaptiveAvgPool2d((1,1)),\n","                  nn.Flatten(),\n","                  nn.Linear(512,176))'''\n","\n","net = timm.create_model('seresnext50_32x4d', pretrained=True)\n","#net=torchvision.models.resnet50(pretrained=True)\n","#net = resnest50(pretrained=True)\n","net.fc = nn.Linear(net.fc.in_features, output_size)\n","\n","#net=torchvision.models.resnet34(pretrained=True)\n","'''for param in net.parameters():\n","    param.requires_grad = False\n","feature = net.fc.in_features \n","net.fc=nn.Linear(feature,output_size)'''\n","\n","\n","if load:  #如果有需要,载入之前的模型\n","  net.load_state_dict(torch.load(model_save_root+model_load_name))\n","\n","if cuda:  #如果有需要，将模型放到GPU上\n","  net=net.cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wq_m08Pp7S6Z"},"outputs":[],"source":["##定义优化器与损失函数\n","\n","#定义优化器\n","optim=torch.optim.AdamW(net.parameters(),lr=lr,weight_decay=weight_decay)\n","scheduler=CosineAnnealingLR(optim,T_max=20)\n","#scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer = optim,T_max=10)\n","\n","#定义损失函数\n","loss=nn.CrossEntropyLoss()\n","if cuda:  #如果有需要，将损失函数放到GPU上\n","  loss=loss.cuda()"]},{"cell_type":"markdown","source":["#训练和验证\n","再用边训练边验证的方法，训练完一轮之后将模型调整为eval模型并进行验证，计算验证集准确率"],"metadata":{"id":"eIw0l_8TVFp1"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"N1IcMf8g80j8","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"398c443d-4d9e-4fab-b911-634992ad207b","executionInfo":{"status":"error","timestamp":1679407496201,"user_tz":-480,"elapsed":282591,"user":{"displayName":"Hikari Lianqing","userId":"02586460300598127694"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["epoch:1 Train [1/201] Loss:5.18085575\n","epoch:1 Train [2/201] Loss:5.15947390\n","epoch:1 Train [3/201] Loss:5.17841053\n","epoch:1 Train [4/201] Loss:5.15496588\n","epoch:1 Train [5/201] Loss:5.17536163\n","epoch:1 Train [6/201] Loss:5.18159866\n","epoch:1 Train [7/201] Loss:5.14347172\n","epoch:1 Train [8/201] Loss:5.14887571\n","epoch:1 Train [9/201] Loss:5.16568041\n","epoch:1 Train [10/201] Loss:5.13528824\n","epoch:1 Train [11/201] Loss:5.16751862\n","epoch:1 Train [12/201] Loss:5.15027428\n","epoch:1 Train [13/201] Loss:5.13566780\n","epoch:1 Train [14/201] Loss:5.14789295\n","epoch:1 Train [15/201] Loss:5.15874481\n","epoch:1 Train [16/201] Loss:5.10456371\n","epoch:1 Train [17/201] Loss:5.15605211\n","epoch:1 Train [18/201] Loss:5.15982342\n","epoch:1 Train [19/201] Loss:5.16157579\n","epoch:1 Train [20/201] Loss:5.11271906\n","epoch:1 Train [21/201] Loss:5.12221479\n","epoch:1 Train [22/201] Loss:5.13442135\n","epoch:1 Train [23/201] Loss:5.12002182\n","epoch:1 Train [24/201] Loss:5.12467575\n","epoch:1 Train [25/201] Loss:5.14973497\n","epoch:1 Train [26/201] Loss:5.07340908\n","epoch:1 Train [27/201] Loss:5.09190369\n","epoch:1 Train [28/201] Loss:5.14537525\n","epoch:1 Train [29/201] Loss:5.10308647\n","epoch:1 Train [30/201] Loss:5.12756777\n","epoch:1 Train [31/201] Loss:5.10454464\n","epoch:1 Train [32/201] Loss:5.10820770\n","epoch:1 Train [33/201] Loss:5.06894684\n","epoch:1 Train [34/201] Loss:5.10275650\n","epoch:1 Train [35/201] Loss:5.06294394\n","epoch:1 Train [36/201] Loss:5.09732294\n","epoch:1 Train [37/201] Loss:5.13709736\n","epoch:1 Train [38/201] Loss:5.07078218\n","epoch:1 Train [39/201] Loss:5.02415943\n","epoch:1 Train [40/201] Loss:5.05738163\n","epoch:1 Train [41/201] Loss:5.10978699\n","epoch:1 Train [42/201] Loss:5.09107018\n","epoch:1 Train [43/201] Loss:5.05937862\n","epoch:1 Train [44/201] Loss:5.04468060\n","epoch:1 Train [45/201] Loss:5.02568960\n","epoch:1 Train [46/201] Loss:5.08956337\n","epoch:1 Train [47/201] Loss:5.01358747\n","epoch:1 Train [48/201] Loss:4.99878597\n","epoch:1 Train [49/201] Loss:5.06485701\n","epoch:1 Train [50/201] Loss:5.08402014\n","epoch:1 Train [51/201] Loss:5.01879978\n","epoch:1 Train [52/201] Loss:5.02814627\n","epoch:1 Train [53/201] Loss:5.04125357\n","epoch:1 Train [54/201] Loss:5.01709509\n","epoch:1 Train [55/201] Loss:5.03294182\n","epoch:1 Train [56/201] Loss:5.05159521\n","epoch:1 Train [57/201] Loss:5.00385714\n","epoch:1 Train [58/201] Loss:4.94516516\n","epoch:1 Train [59/201] Loss:4.98709917\n","epoch:1 Train [60/201] Loss:5.02691174\n","epoch:1 Train [61/201] Loss:4.95412350\n","epoch:1 Train [62/201] Loss:5.02739573\n","epoch:1 Train [63/201] Loss:4.90572309\n","epoch:1 Train [64/201] Loss:5.04011440\n","epoch:1 Train [65/201] Loss:4.97125483\n","epoch:1 Train [66/201] Loss:4.84742069\n","epoch:1 Train [67/201] Loss:4.86098146\n","epoch:1 Train [68/201] Loss:4.98455048\n","epoch:1 Train [69/201] Loss:4.98320866\n","epoch:1 Train [70/201] Loss:4.85145664\n","epoch:1 Train [71/201] Loss:5.00084305\n","epoch:1 Train [72/201] Loss:4.92769146\n","epoch:1 Train [73/201] Loss:4.96041393\n","epoch:1 Train [74/201] Loss:4.86996222\n","epoch:1 Train [75/201] Loss:4.95900440\n","epoch:1 Train [76/201] Loss:4.88369846\n","epoch:1 Train [77/201] Loss:4.83395863\n","epoch:1 Train [78/201] Loss:4.91126299\n","epoch:1 Train [79/201] Loss:4.77419615\n","epoch:1 Train [80/201] Loss:4.91998005\n","epoch:1 Train [81/201] Loss:4.75221252\n","epoch:1 Train [82/201] Loss:4.83920097\n","epoch:1 Train [83/201] Loss:4.84096909\n","epoch:1 Train [84/201] Loss:4.86072969\n","epoch:1 Train [85/201] Loss:4.68368626\n","epoch:1 Train [86/201] Loss:4.82996130\n","epoch:1 Train [87/201] Loss:4.78382063\n","epoch:1 Train [88/201] Loss:4.71831274\n","epoch:1 Train [89/201] Loss:4.63308287\n","epoch:1 Train [90/201] Loss:4.72978306\n","epoch:1 Train [91/201] Loss:4.81861448\n","epoch:1 Train [92/201] Loss:4.57217789\n","epoch:1 Train [93/201] Loss:4.64686584\n","epoch:1 Train [94/201] Loss:4.86816120\n","epoch:1 Train [95/201] Loss:4.67246008\n","epoch:1 Train [96/201] Loss:4.60092545\n","epoch:1 Train [97/201] Loss:4.74457264\n","epoch:1 Train [98/201] Loss:4.61890984\n","epoch:1 Train [99/201] Loss:4.60221958\n","epoch:1 Train [100/201] Loss:4.66863394\n","epoch:1 Train [101/201] Loss:4.67485332\n","epoch:1 Train [102/201] Loss:4.60252810\n","epoch:1 Train [103/201] Loss:4.67741442\n","epoch:1 Train [104/201] Loss:4.46655416\n","epoch:1 Train [105/201] Loss:4.46189070\n","epoch:1 Train [106/201] Loss:4.57073689\n","epoch:1 Train [107/201] Loss:4.54867649\n","epoch:1 Train [108/201] Loss:4.58214951\n","epoch:1 Train [109/201] Loss:4.45047522\n","epoch:1 Train [110/201] Loss:4.68881750\n","epoch:1 Train [111/201] Loss:4.42530060\n","epoch:1 Train [112/201] Loss:4.53881550\n","epoch:1 Train [113/201] Loss:4.36192894\n","epoch:1 Train [114/201] Loss:4.34840488\n","epoch:1 Train [115/201] Loss:4.35748100\n","epoch:1 Train [116/201] Loss:4.39715433\n","epoch:1 Train [117/201] Loss:4.57446241\n","epoch:1 Train [118/201] Loss:4.33118773\n","epoch:1 Train [119/201] Loss:4.34529400\n","epoch:1 Train [120/201] Loss:4.44147158\n","epoch:1 Train [121/201] Loss:4.43247366\n","epoch:1 Train [122/201] Loss:4.35004234\n","epoch:1 Train [123/201] Loss:4.25116396\n","epoch:1 Train [124/201] Loss:4.32109642\n","epoch:1 Train [125/201] Loss:4.35967064\n","epoch:1 Train [126/201] Loss:4.21952677\n","epoch:1 Train [127/201] Loss:4.25789452\n","epoch:1 Train [128/201] Loss:4.04307175\n","epoch:1 Train [129/201] Loss:4.17726231\n","epoch:1 Train [130/201] Loss:4.34727430\n","epoch:1 Train [131/201] Loss:4.15982437\n","epoch:1 Train [132/201] Loss:4.41304064\n","epoch:1 Train [133/201] Loss:4.22815704\n","epoch:1 Train [134/201] Loss:4.27465916\n","epoch:1 Train [135/201] Loss:4.10470915\n","epoch:1 Train [136/201] Loss:4.08016348\n","epoch:1 Train [137/201] Loss:4.02183390\n","epoch:1 Train [138/201] Loss:4.04942513\n","epoch:1 Train [139/201] Loss:4.16354132\n","epoch:1 Train [140/201] Loss:4.03212833\n","epoch:1 Train [141/201] Loss:4.02583027\n","epoch:1 Train [142/201] Loss:4.10362959\n","epoch:1 Train [143/201] Loss:3.76245117\n","epoch:1 Train [144/201] Loss:4.16672659\n","epoch:1 Train [145/201] Loss:4.12464237\n","epoch:1 Train [146/201] Loss:4.23443222\n","epoch:1 Train [147/201] Loss:4.25008774\n","epoch:1 Train [148/201] Loss:3.66226029\n","epoch:1 Train [149/201] Loss:3.67653561\n","epoch:1 Train [150/201] Loss:4.02761841\n","epoch:1 Train [151/201] Loss:3.82011843\n","epoch:1 Train [152/201] Loss:3.86402631\n","epoch:1 Train [153/201] Loss:4.10287857\n","epoch:1 Train [154/201] Loss:3.96411133\n","epoch:1 Train [155/201] Loss:4.01458979\n","epoch:1 Train [156/201] Loss:3.64364123\n","epoch:1 Train [157/201] Loss:3.73284006\n","epoch:1 Train [158/201] Loss:3.63025832\n","epoch:1 Train [159/201] Loss:3.70625353\n","epoch:1 Train [160/201] Loss:3.70706677\n","epoch:1 Train [161/201] Loss:3.74900413\n","epoch:1 Train [162/201] Loss:3.82557201\n","epoch:1 Train [163/201] Loss:3.59302044\n","epoch:1 Train [164/201] Loss:3.93344069\n","epoch:1 Train [165/201] Loss:3.42385769\n","epoch:1 Train [166/201] Loss:3.70381832\n","epoch:1 Train [167/201] Loss:3.68547058\n","epoch:1 Train [168/201] Loss:3.46010327\n","epoch:1 Train [169/201] Loss:3.63114643\n","epoch:1 Train [170/201] Loss:3.53702354\n","epoch:1 Train [171/201] Loss:3.41780686\n","epoch:1 Train [172/201] Loss:3.48523569\n","epoch:1 Train [173/201] Loss:3.70810223\n","epoch:1 Train [174/201] Loss:3.64046288\n","epoch:1 Train [175/201] Loss:3.53926134\n","epoch:1 Train [176/201] Loss:3.26858211\n","epoch:1 Train [177/201] Loss:3.54389548\n","epoch:1 Train [178/201] Loss:3.66145658\n","epoch:1 Train [179/201] Loss:3.70192409\n","epoch:1 Train [180/201] Loss:3.23056173\n","epoch:1 Train [181/201] Loss:3.40707016\n","epoch:1 Train [182/201] Loss:3.33368421\n","epoch:1 Train [183/201] Loss:3.42838430\n","epoch:1 Train [184/201] Loss:3.24195337\n","epoch:1 Train [185/201] Loss:3.20413923\n","epoch:1 Train [186/201] Loss:3.21233273\n","epoch:1 Train [187/201] Loss:3.24749184\n","epoch:1 Train [188/201] Loss:3.37415433\n","epoch:1 Train [189/201] Loss:3.38229513\n","epoch:1 Train [190/201] Loss:3.28726053\n","epoch:1 Train [191/201] Loss:3.33437967\n","epoch:1 Train [192/201] Loss:3.33740544\n","epoch:1 Train [193/201] Loss:3.12589288\n","epoch:1 Train [194/201] Loss:3.17297673\n","epoch:1 Train [195/201] Loss:3.23177075\n","epoch:1 Train [196/201] Loss:3.13141823\n","epoch:1 Train [197/201] Loss:3.28427887\n","epoch:1 Train [198/201] Loss:3.17774868\n","epoch:1 Train [199/201] Loss:3.36204433\n","epoch:1 Train [200/201] Loss:3.27593422\n","epoch:1 Train [201/201] Loss:3.21007133\n","第2个epoch的学习率：0.000100\n","[1/50] |Train Loss: 0.06940508, Acc: 0.1081\n","epoch:1 Val [1/87]\n","epoch:1 Val [2/87]\n","epoch:1 Val [3/87]\n","epoch:1 Val [4/87]\n","epoch:1 Val [5/87]\n","epoch:1 Val [6/87]\n","epoch:1 Val [7/87]\n","epoch:1 Val [8/87]\n","epoch:1 Val [9/87]\n","epoch:1 Val [10/87]\n","epoch:1 Val [11/87]\n","epoch:1 Val [12/87]\n","epoch:1 Val [13/87]\n","epoch:1 Val [14/87]\n","epoch:1 Val [15/87]\n","epoch:1 Val [16/87]\n","epoch:1 Val [17/87]\n","epoch:1 Val [18/87]\n","epoch:1 Val [19/87]\n","epoch:1 Val [20/87]\n","epoch:1 Val [21/87]\n","epoch:1 Val [22/87]\n","epoch:1 Val [23/87]\n","epoch:1 Val [24/87]\n","epoch:1 Val [25/87]\n","epoch:1 Val [26/87]\n","epoch:1 Val [27/87]\n","epoch:1 Val [28/87]\n","epoch:1 Val [29/87]\n","epoch:1 Val [30/87]\n","epoch:1 Val [31/87]\n","epoch:1 Val [32/87]\n","epoch:1 Val [33/87]\n","epoch:1 Val [34/87]\n","epoch:1 Val [35/87]\n","epoch:1 Val [36/87]\n","epoch:1 Val [37/87]\n","epoch:1 Val [38/87]\n","epoch:1 Val [39/87]\n","epoch:1 Val [40/87]\n","epoch:1 Val [41/87]\n","epoch:1 Val [42/87]\n","epoch:1 Val [43/87]\n","epoch:1 Val [44/87]\n","epoch:1 Val [45/87]\n","epoch:1 Val [46/87]\n","epoch:1 Val [47/87]\n","epoch:1 Val [48/87]\n","epoch:1 Val [49/87]\n","epoch:1 Val [50/87]\n","epoch:1 Val [51/87]\n","epoch:1 Val [52/87]\n","epoch:1 Val [53/87]\n","epoch:1 Val [54/87]\n","epoch:1 Val [55/87]\n","epoch:1 Val [56/87]\n","epoch:1 Val [57/87]\n","epoch:1 Val [58/87]\n","epoch:1 Val [59/87]\n","epoch:1 Val [60/87]\n","epoch:1 Val [61/87]\n","epoch:1 Val [62/87]\n","epoch:1 Val [63/87]\n","epoch:1 Val [64/87]\n","epoch:1 Val [65/87]\n","epoch:1 Val [66/87]\n","epoch:1 Val [67/87]\n","epoch:1 Val [68/87]\n","epoch:1 Val [69/87]\n","epoch:1 Val [70/87]\n","epoch:1 Val [71/87]\n","epoch:1 Val [72/87]\n","epoch:1 Val [73/87]\n","epoch:1 Val [74/87]\n","epoch:1 Val [75/87]\n","epoch:1 Val [76/87]\n","epoch:1 Val [77/87]\n","epoch:1 Val [78/87]\n","epoch:1 Val [79/87]\n","epoch:1 Val [80/87]\n","epoch:1 Val [81/87]\n","epoch:1 Val [82/87]\n","epoch:1 Val [83/87]\n","epoch:1 Val [84/87]\n","epoch:1 Val [85/87]\n","epoch:1 Val [86/87]\n","epoch:1 Val [87/87]\n","|Val Loss: 0.04799335, Acc: 0.2726\n","epoch:2 Train [1/201] Loss:3.22695494\n","epoch:2 Train [2/201] Loss:2.99699473\n","epoch:2 Train [3/201] Loss:3.21682119\n","epoch:2 Train [4/201] Loss:3.40859675\n","epoch:2 Train [5/201] Loss:3.13327694\n","epoch:2 Train [6/201] Loss:3.11141133\n","epoch:2 Train [7/201] Loss:3.03916287\n","epoch:2 Train [8/201] Loss:3.11605000\n","epoch:2 Train [9/201] Loss:3.34917665\n","epoch:2 Train [10/201] Loss:2.91858768\n","epoch:2 Train [11/201] Loss:3.11615014\n","epoch:2 Train [12/201] Loss:3.03555608\n","epoch:2 Train [13/201] Loss:3.36932707\n","epoch:2 Train [14/201] Loss:2.71729517\n","epoch:2 Train [15/201] Loss:3.04678178\n","epoch:2 Train [16/201] Loss:3.05678272\n","epoch:2 Train [17/201] Loss:2.96222663\n","epoch:2 Train [18/201] Loss:3.05637407\n","epoch:2 Train [19/201] Loss:3.11011076\n","epoch:2 Train [20/201] Loss:2.95396829\n","epoch:2 Train [21/201] Loss:2.91052604\n","epoch:2 Train [22/201] Loss:3.07674623\n","epoch:2 Train [23/201] Loss:2.85541248\n","epoch:2 Train [24/201] Loss:3.04016185\n","epoch:2 Train [25/201] Loss:2.83996844\n","epoch:2 Train [26/201] Loss:3.09864211\n","epoch:2 Train [27/201] Loss:2.95700192\n","epoch:2 Train [28/201] Loss:2.95797944\n","epoch:2 Train [29/201] Loss:2.92782092\n","epoch:2 Train [30/201] Loss:2.78491879\n","epoch:2 Train [31/201] Loss:3.11155772\n","epoch:2 Train [32/201] Loss:2.99540758\n","epoch:2 Train [33/201] Loss:2.90108347\n","epoch:2 Train [34/201] Loss:2.96688223\n","epoch:2 Train [35/201] Loss:2.58858371\n","epoch:2 Train [36/201] Loss:2.82384777\n","epoch:2 Train [37/201] Loss:2.89456773\n","epoch:2 Train [38/201] Loss:2.93481374\n","epoch:2 Train [39/201] Loss:2.61769772\n","epoch:2 Train [40/201] Loss:2.68701887\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-10cf5a115bfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch:%d Train [%d/%d] Loss:%.8f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mload_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             adamw(params_with_grad,\n\u001b[0m\u001b[1;32m    163\u001b[0m                   \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                   \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adamw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    220\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;31m# Perform stepweight decay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["##训练和验证\n","for epoch in range(1,epochs+1):\n","  net.train()\n","  total_acc=0\n","  total_loss=0\n","  for i,(image,label) in enumerate(train_iter):\n","    if cuda:  #如果有需要，将数据放到GPU上\n","      image=image.cuda()\n","      label=label.cuda()\n","    optim.zero_grad() #梯度清零\n","    output=net(image) #前向传播\n","    l=loss(output,label)  #计算损失\n","    total_loss+=l #损失累计\n","    total_acc+=torch.sum(torch.argmax(output,dim=1)==label)  #当前预测正确的数目\n","      \n","    l.backward()\n","    optim.step()\n","\n","    print(\"epoch:%d Train [%d/%d] Loss:%.8f\"%(epoch+load_epoch,i+1,int(len(train_set)/batch_size)+1,l))\n","\n","  print(\"第%d个epoch的学习率：%f\" % (epoch+1,optim.param_groups[0]['lr']))\n","  scheduler.step()\n","\n","  acc=total_acc/len(train_image)\n","  avg_loss=total_loss/len(train_image)\n","  print(\"[%d/%d] |Train Loss: %.8f, Acc: %.4f\" % (epoch+load_epoch,epochs+load_epoch,avg_loss,acc))\n","\n","  torch.save(net.state_dict(),model_save_root+\"seresnext_epoch{}.pth\".format(epoch+load_epoch)) #模型保存\n","\n","  net.eval()  #禁用BN\n","  total_acc=0\n","  total_loss=0\n","  \n","  for i,(image,label) in enumerate(val_iter):\n","    if cuda:  #如果有需要，将数据放到GPU上\n","      image=image.cuda()\n","      label=label.cuda()\n","      \n","    with torch.no_grad(): #不计算梯度\n","      output=net(image) #前向传播\n","      l=loss(output,label)  #计算损失\n","\n","    total_loss+=l #损失累计\n","    total_acc+=torch.sum(torch.argmax(output,dim=1)==label)  #当前预测正确的数目\n","\n","    print(\"epoch:%d Val [%d/%d]\"%(epoch+load_epoch,i+1,int(len(val_set)/batch_size)+1))\n","  \n","  acc=total_acc/len(val_image)\n","  avg_loss=total_loss/len(val_image)\n","  print(\"|Val Loss: %.8f, Acc: %.4f\" % (avg_loss,acc))"]},{"cell_type":"markdown","source":["#测试"],"metadata":{"id":"YvLYMCImpq85"}},{"cell_type":"code","source":["#model = timm.create_model('seresnext50_32x4d')\n","model=torchvision.models.resnet18(pretrained=False)\n","model.fc = nn.Linear(net.fc.in_features, output_size)\n","if cuda:\n","  model.cuda()\n","load_path=\"/content/drive/MyDrive/LeavesClassification/alexnet_epoch70.pth\"\n","model.load_state_dict(torch.load(load_path))\n","\n","model.eval()\n","\n","predictions=[]\n","\n","for i,image in enumerate(test_iter):\n","  if cuda:\n","    image=image.cuda()\n","  with torch.no_grad():\n","    output=model(image)\n","\n","  predictions.extend(torch.argmax(output,dim=1).cpu().numpy().tolist())\n","\n","preds=[]\n","for i in predictions:\n","  preds.append(id_to_label[i])\n","\n","test_csv[\"label\"]=pd.Series(preds)\n","submission = pd.concat([test_csv['image'], test_csv['label']], axis=1)\n","submission.to_csv(\"/content/drive/MyDrive/LeavesClassification/submission_resnet18_70.csv\", index=False)\n","print(\"Done!!!!!!!!!!!!!!!!!!!!!!!!!!!\")"],"metadata":{"id":"WMuccNhtpqCp"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMmbX/lYdx3rTcAUE2keWkd"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}